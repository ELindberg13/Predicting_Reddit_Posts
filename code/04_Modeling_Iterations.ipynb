{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.506923\n",
       "1    0.493077\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the cleaned reddit posts\n",
    "posts = pd.read_csv(\"../data/cleaned_reddit_posts.csv\")\n",
    "\n",
    "X = posts[\"title\"]\n",
    "y = posts[\"subreddit\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=2020)\n",
    "\n",
    "#Calculating the baseline accuracy of the data\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# adding eli5, aita, and wibta to the stopwords\n",
    "stopwords.extend(['eli5','aita','wibta','friend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create dictionary of model params and counter\n",
    "logreg_model_df = pd.read_csv(\"../data/logreg_model_params.csv\")\n",
    "\n",
    "#getting the index from the nb_model_params and saving it to a count\n",
    "logreg_count = logreg_model_df.tail(1).index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 1.2991981506347656 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>logreg__C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.923462</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.922308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.961026</td>\n",
       "      <td>0.919615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.961026</td>\n",
       "      <td>0.919615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.951154</td>\n",
       "      <td>0.913077</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.961026</td>\n",
       "      <td>0.919615</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950769</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926538</td>\n",
       "      <td>0.901154</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.929359</td>\n",
       "      <td>0.904231</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.932821</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926538</td>\n",
       "      <td>0.901154</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926154</td>\n",
       "      <td>0.901923</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.928718</td>\n",
       "      <td>0.906154</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.928718</td>\n",
       "      <td>0.906154</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926154</td>\n",
       "      <td>0.901923</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.929359</td>\n",
       "      <td>0.903077</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955897</td>\n",
       "      <td>0.919615</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.918462</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955897</td>\n",
       "      <td>0.919615</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926154</td>\n",
       "      <td>0.901923</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_20</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955897</td>\n",
       "      <td>0.919615</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cvec__max_df  cvec__max_features  cvec__min_df  train score  \\\n",
       "0                  0.7                3000             2     0.970000   \n",
       "1                  0.7                2500             3     0.966667   \n",
       "2                  0.7                2000             4     0.961026   \n",
       "3                  0.6                2000             4     0.961026   \n",
       "4                  0.8                1500             3     0.951154   \n",
       "5                  0.8                2000             4     0.961026   \n",
       "6                  0.8                2000             3     0.950769   \n",
       "7                  0.8                2000             3     0.926538   \n",
       "8                  0.8                2500             3     0.929359   \n",
       "9                  0.8                3000             3     0.932821   \n",
       "10                 0.8                2000             3     0.926538   \n",
       "11                 0.8                2000             2     0.926154   \n",
       "12                 0.8                2000             2     0.928718   \n",
       "13                 0.8                2000             2     0.928718   \n",
       "14                 0.8                2000             2     0.926154   \n",
       "15                 0.8                2500             2     0.929359   \n",
       "16                 0.8                2500             2     0.955897   \n",
       "17                 0.8                2500             3     0.955769   \n",
       "18                 0.8                2500             2     0.955897   \n",
       "19                 0.8                2000             2     0.926154   \n",
       "model_20           0.8                2500             2     0.955897   \n",
       "\n",
       "          test score  logreg__C  \n",
       "0           0.923462        NaN  \n",
       "1           0.922308        NaN  \n",
       "2           0.919615        NaN  \n",
       "3           0.919615        NaN  \n",
       "4           0.913077        NaN  \n",
       "5           0.919615        1.0  \n",
       "6           0.915385        0.5  \n",
       "7           0.901154        0.1  \n",
       "8           0.904231        0.1  \n",
       "9           0.905000        0.1  \n",
       "10          0.901154        0.1  \n",
       "11          0.901923        0.1  \n",
       "12          0.906154        0.1  \n",
       "13          0.906154        0.1  \n",
       "14          0.901923        0.1  \n",
       "15          0.903077        0.1  \n",
       "16          0.919615        0.5  \n",
       "17          0.918462        0.5  \n",
       "18          0.919615        0.5  \n",
       "19          0.901923        0.1  \n",
       "model_20    0.919615        0.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords)),\n",
    "    ('logreg', LogisticRegression(penalty=\"l2\",solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "logreg_pipe_params = {\n",
    "    \"cvec__max_features\" : [2500],\n",
    "    \"cvec__min_df\" : [2],\n",
    "    \"cvec__max_df\" : [.80],\n",
    "    \"logreg__C\" : [.5]\n",
    "}\n",
    "\n",
    "temp_dict = {}\n",
    "t0 = time.time()\n",
    "\n",
    "logreg_gs = GridSearchCV(logreg_pipe,param_grid=logreg_pipe_params,cv=5,verbose=1)\n",
    "\n",
    "logreg_gs.fit(X_train,y_train)\n",
    "\n",
    "best_logreg = logreg_gs.best_estimator_\n",
    "\n",
    "logreg_count += 1\n",
    "\n",
    "logreg_gs.best_params_[\"train score\"] = best_logreg.score(X_train,y_train)\n",
    "logreg_gs.best_params_[\"test score\"] = best_logreg.score(X_test,y_test)\n",
    "temp_dict[f'model_{logreg_count}'] = logreg_gs.best_params_\n",
    "\n",
    "temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "logreg_model_df = pd.concat([logreg_model_df,temp_df])\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'This took {t1-t0} seconds!')\n",
    "\n",
    "logreg_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_df.to_csv(\"../data/logreg_model_params.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords)),\n",
    "    ('to_dense' , DenseTransformer()),\n",
    "    ('ss', StandardScaler(with_mean=True)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# knn_pipe_params = {\n",
    "#     \"cvec__max_features\" : [1000,2000,3000],\n",
    "#     \"cvec__min_df\" : [2,3,4],\n",
    "#     \"cvec__max_df\" : [.7,.8,.9],\n",
    "#     \"knn__n_neighbors\" : [3,11,25],\n",
    "#     'knn__weights': [\"uniform\",\"distance\"]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took 4418.813382148743 seconds!\n",
    " Best parameters {'cvec__max_df': 0.7, 'cvec__max_features': 1000, 'cvec__min_df': 4, 'knn__n_neighbors': 11, 'knn__weights': 'distance'}\n",
    " Training score 0.9876190476190476\n",
    " Training score 0.8447619047619047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran a gridsearch to search hyperparameters for KNN\n",
    "# knn_gs = GridSearchCV(knn_pipe,param_grid=knn_pipe_params,cv=5,verbose=2)\n",
    "# knn_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_knn = knn_gs.best_estimator_\n",
    "\n",
    "# t1 = time.time()\n",
    "# print(f'This took {t1-t0} seconds!')\n",
    "# print(f' Best parameters {knn_gs.best_params_}')\n",
    "# print(f' Training score {best_knn.score(X_train,y_train)}')\n",
    "# print(f' Testing score {best_knn.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 107.95248818397522 seconds!\n",
      " Best parameters {'cvec__max_df': 0.7, 'cvec__max_features': 1000, 'cvec__min_df': 4, 'knn__n_neighbors': 11, 'knn__weights': 'distance'}\n",
      " Training score 0.9793589743589743\n",
      " Testing score 0.8511538461538461\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "knn_pipe_params = {\n",
    "    \"cvec__max_features\" : [1000],\n",
    "    \"cvec__min_df\" : [4],\n",
    "    \"cvec__max_df\" : [.7],\n",
    "    \"knn__n_neighbors\" : [11],\n",
    "    'knn__weights': [\"distance\"]\n",
    "}\n",
    "\n",
    "knn_gs = GridSearchCV(knn_pipe,param_grid=knn_pipe_params,cv=5,verbose=1)\n",
    "knn_gs.fit(X_train,y_train)\n",
    "\n",
    "best_knn = knn_gs.best_estimator_\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'This took {t1-t0} seconds!')\n",
    "print(f' Best parameters {knn_gs.best_params_}')\n",
    "print(f' Training score {best_knn.score(X_train,y_train)}')\n",
    "print(f' Testing score {best_knn.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall KNN has too high of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create dictionary of model params and counter\n",
    "nb_model_df = pd.read_csv(\"../data/nb_model_para.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the index from the nb_model_params and saving it to a count\n",
    "nb_count = nb_model_df.tail(1).index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 1.5051231384277344 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.959365</td>\n",
       "      <td>0.918095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.964444</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.959365</td>\n",
       "      <td>0.918095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.948889</td>\n",
       "      <td>0.909524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.933846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.944872</td>\n",
       "      <td>0.929231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952179</td>\n",
       "      <td>0.932308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.931538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952179</td>\n",
       "      <td>0.932308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952179</td>\n",
       "      <td>0.932308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cvec__max_df  cvec__max_features  cvec__min_df  train score  \\\n",
       "0                 0.7                1500             3     0.959365   \n",
       "1                 0.6                2000             2     0.964444   \n",
       "2                 0.6                1500             3     0.959365   \n",
       "3                 0.7                1500             4     0.948889   \n",
       "4                 0.8                2000             3     0.949359   \n",
       "5                 0.8                2000             3     0.944872   \n",
       "6                 0.8                2500             3     0.952179   \n",
       "7                 0.8                2500             2     0.951538   \n",
       "8                 0.8                2500             3     0.952179   \n",
       "model_9           0.8                2500             3     0.952179   \n",
       "\n",
       "         test score  \n",
       "0          0.918095  \n",
       "1          0.914286  \n",
       "2          0.918095  \n",
       "3          0.909524  \n",
       "4          0.933846  \n",
       "5          0.929231  \n",
       "6          0.932308  \n",
       "7          0.931538  \n",
       "8          0.932308  \n",
       "model_9    0.932308  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict = {}\n",
    "t0 = time.time()\n",
    "nb_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "nb_pipe_params = {\n",
    "    \"cvec__max_features\" : [2500],\n",
    "    \"cvec__min_df\" : [3],\n",
    "    \"cvec__max_df\" : [.8],\n",
    "}\n",
    "\n",
    "nb_gs = GridSearchCV(nb_pipe,param_grid=nb_pipe_params,cv=5,verbose=1)\n",
    "nb_gs.fit(X_train,y_train)\n",
    "\n",
    "best_nb = nb_gs.best_estimator_\n",
    "\n",
    "nb_count += 1\n",
    "\n",
    "nb_gs.best_params_[\"train score\"] = best_nb.score(X_train,y_train)\n",
    "nb_gs.best_params_[\"test score\"] = best_nb.score(X_test,y_test)\n",
    "temp_dict[f'model_{nb_count}'] = nb_gs.best_params_\n",
    "\n",
    "temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "nb_model_df = pd.concat([nb_model_df,temp_df])\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'This took {t1-t0} seconds!')\n",
    "\n",
    "nb_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_df.to_csv(\"../data/nb_model_para.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes does an equally good job of predicting subreddits as logisitic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create dictionary of model params and counter\n",
    "dt_model_df = pd.read_csv(\"../data/dt_model_params.csv\")\n",
    "\n",
    "#getting the index from the nb_model_params and saving it to a count\n",
    "dt_count = dt_model_df.tail(1).index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 2.9272680282592773 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>dt__ccp_alpha</th>\n",
       "      <th>dt__max_depth</th>\n",
       "      <th>dt__min_samples_leaf</th>\n",
       "      <th>dt__min_samples_split</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.731282</td>\n",
       "      <td>0.727308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813077</td>\n",
       "      <td>0.805385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.870641</td>\n",
       "      <td>0.859231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.911795</td>\n",
       "      <td>0.888462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.921795</td>\n",
       "      <td>0.895385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.921923</td>\n",
       "      <td>0.892308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.924231</td>\n",
       "      <td>0.891538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.923590</td>\n",
       "      <td>0.891538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.923590</td>\n",
       "      <td>0.891538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.915897</td>\n",
       "      <td>0.873462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_11</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.915897</td>\n",
       "      <td>0.873462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cvec__max_df  cvec__max_features  cvec__min_df  dt__ccp_alpha  \\\n",
       "0                  0.8                2000             2              0   \n",
       "1                  0.8                2000             2              0   \n",
       "2                  0.8                2000             2              0   \n",
       "3                  0.8                2000             2              0   \n",
       "4                  0.8                2000             2              0   \n",
       "5                  0.8                2000             2              0   \n",
       "6                  0.8                2000             2              0   \n",
       "7                  0.8                3000             3              0   \n",
       "8                  0.8                2500             3              0   \n",
       "9                  0.8                2500             3              0   \n",
       "10                 0.8                2500             3              0   \n",
       "model_11           0.8                2500             3              0   \n",
       "\n",
       "          dt__max_depth  dt__min_samples_leaf  dt__min_samples_split  \\\n",
       "0                     9                     3                      5   \n",
       "1                    20                     3                      5   \n",
       "2                    40                     3                      5   \n",
       "3                    60                     3                      5   \n",
       "4                   100                     3                      5   \n",
       "5                   150                     3                     15   \n",
       "6                   200                     3                     20   \n",
       "7                   200                     3                     20   \n",
       "8                   250                     3                     20   \n",
       "9                   250                     3                     20   \n",
       "10                  250                     3                     20   \n",
       "model_11            250                     3                     20   \n",
       "\n",
       "          train score  test score  \n",
       "0            0.731282    0.727308  \n",
       "1            0.813077    0.805385  \n",
       "2            0.870641    0.859231  \n",
       "3            0.891026    0.875000  \n",
       "4            0.911795    0.888462  \n",
       "5            0.921795    0.895385  \n",
       "6            0.921923    0.892308  \n",
       "7            0.924231    0.891538  \n",
       "8            0.923590    0.891538  \n",
       "9            0.923590    0.891538  \n",
       "10           0.915897    0.873462  \n",
       "model_11     0.915897    0.873462  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=2020))\n",
    "])\n",
    "\n",
    "dt_pipe_params = {\n",
    "    \"cvec__max_features\" : [2500],\n",
    "    \"cvec__min_df\" : [3],\n",
    "    \"cvec__max_df\" : [.80],\n",
    "    \"dt__max_depth\" : [250],\n",
    "    \"dt__min_samples_leaf\" : [3],\n",
    "    \"dt__min_samples_split\" : [20],\n",
    "    \"dt__ccp_alpha\" : [0]\n",
    "}\n",
    "\n",
    "temp_dict = {}\n",
    "t0 = time.time()\n",
    "\n",
    "dt_gs = GridSearchCV(dt_pipe,param_grid=dt_pipe_params,cv=5,verbose=1)\n",
    "\n",
    "dt_gs.fit(X_train,y_train)\n",
    "\n",
    "best_dt = dt_gs.best_estimator_\n",
    "\n",
    "dt_count += 1\n",
    "\n",
    "dt_gs.best_params_[\"train score\"] = best_dt.score(X_train,y_train)\n",
    "dt_gs.best_params_[\"test score\"] = best_dt.score(X_test,y_test)\n",
    "temp_dict[f'model_{dt_count}'] = dt_gs.best_params_\n",
    "\n",
    "temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "dt_model_df = pd.concat([dt_model_df,temp_df])\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'This took {t1-t0} seconds!')\n",
    "\n",
    "dt_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_df.to_csv(\"../data/dt_model_params.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decsison tree provides a good (but not great) predicition of subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create dictionary of model params and counter\n",
    "rf_model_df = pd.read_csv(\"../data/rf_model_params.csv\")\n",
    "\n",
    "#getting the index from the nb_model_params and saving it to a count\n",
    "rf_count = rf_model_df.tail(1).index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 5.077329397201538 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>rf__ccp_alpha</th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__min_samples_leaf</th>\n",
       "      <th>rf__min_samples_split</th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>0.925513</td>\n",
       "      <td>0.902692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.922692</td>\n",
       "      <td>0.902308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.930641</td>\n",
       "      <td>0.904615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0.934231</td>\n",
       "      <td>0.905769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0.934231</td>\n",
       "      <td>0.905769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0.923974</td>\n",
       "      <td>0.889615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0.923974</td>\n",
       "      <td>0.889615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cvec__max_df  cvec__max_features  cvec__min_df  rf__ccp_alpha  \\\n",
       "0                 0.8                2500             3              0   \n",
       "1                 0.8                3000             3              0   \n",
       "2                 0.8                2500             3              0   \n",
       "3                 0.8                2500             3              0   \n",
       "4                 0.8                2500             3              0   \n",
       "5                 0.8                2500             3              0   \n",
       "model_6           0.8                2500             3              0   \n",
       "\n",
       "         rf__max_depth  rf__min_samples_leaf  rf__min_samples_split  \\\n",
       "0                  225                     3                     15   \n",
       "1                  200                     3                     20   \n",
       "2                  200                     2                     20   \n",
       "3                  225                     2                     25   \n",
       "4                  225                     2                     25   \n",
       "5                  225                     2                     25   \n",
       "model_6            225                     2                     25   \n",
       "\n",
       "         rf__n_estimators  train score  test score  \n",
       "0                      50     0.925513    0.902692  \n",
       "1                      50     0.922692    0.902308  \n",
       "2                      50     0.930641    0.904615  \n",
       "3                      50     0.934231    0.905769  \n",
       "4                      50     0.934231    0.905769  \n",
       "5                      50     0.923974    0.889615  \n",
       "model_6                50     0.923974    0.889615  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords)),\n",
    "    ('rf', RandomForestClassifier(random_state=2020))\n",
    "])\n",
    "\n",
    "rf_pipe_params = {\n",
    "    \"cvec__max_features\" : [2500],\n",
    "    \"cvec__min_df\" : [3],\n",
    "    \"cvec__max_df\" : [.80],\n",
    "    \"rf__n_estimators\" : [50],\n",
    "    \"rf__max_depth\" : [225],\n",
    "    \"rf__min_samples_leaf\" : [2],\n",
    "    \"rf__min_samples_split\" : [25],\n",
    "    \"rf__ccp_alpha\" : [0]\n",
    "}\n",
    "\n",
    "temp_dict = {}\n",
    "t0 = time.time()\n",
    "\n",
    "rf_gs = GridSearchCV(rf_pipe,param_grid=rf_pipe_params,cv=5,verbose=1)\n",
    "\n",
    "rf_gs.fit(X_train,y_train)\n",
    "\n",
    "best_rf = rf_gs.best_estimator_\n",
    "\n",
    "rf_count += 1\n",
    "\n",
    "rf_gs.best_params_[\"train score\"] = best_rf.score(X_train,y_train)\n",
    "rf_gs.best_params_[\"test score\"] = best_rf.score(X_test,y_test)\n",
    "temp_dict[f'model_{rf_count}'] = rf_gs.best_params_\n",
    "\n",
    "temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "rf_model_df = pd.concat([rf_model_df,temp_df])\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'This took {t1-t0} seconds!')\n",
    "\n",
    "rf_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_df.to_csv(\"../data/rf_model_params.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf model conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create dictionary of model params and counter\n",
    "ada_model_df = pd.read_csv(\"../data/ada_model_params.csv\")\n",
    "\n",
    "#getting the index from the nb_model_params and saving it to a count\n",
    "ada_count = ada_model_df.tail(1).index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 12.34099006652832 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada__n_estimators</th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.892436</td>\n",
       "      <td>0.876538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.895769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.932436</td>\n",
       "      <td>0.898462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.932436</td>\n",
       "      <td>0.898462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.883077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.882308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.883077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.883077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ada__n_estimators  cvec__max_df  cvec__max_features  cvec__min_df  \\\n",
       "0                      100           0.8                2000             2   \n",
       "1                      200           0.8                2000             3   \n",
       "2                      250           0.8                1500             2   \n",
       "3                      250           0.8                1500             2   \n",
       "4                      250           0.8                1500             2   \n",
       "5                      250           0.8                2000             2   \n",
       "6                      250           0.8                1500             2   \n",
       "model_7                250           0.8                1500             2   \n",
       "\n",
       "         train score  test score  \n",
       "0           0.892436    0.876538  \n",
       "1           0.923333    0.895769  \n",
       "2           0.932436    0.898462  \n",
       "3           0.932436    0.898462  \n",
       "4           0.921026    0.883077  \n",
       "5           0.921026    0.882308  \n",
       "6           0.921026    0.883077  \n",
       "model_7     0.921026    0.883077  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords)),\n",
    "    ('ada', AdaBoostClassifier(random_state=2020))\n",
    "])\n",
    "\n",
    "ada_pipe_params = {\n",
    "    \"cvec__max_features\" : [1500],\n",
    "    \"cvec__min_df\" : [2],\n",
    "    \"cvec__max_df\" : [.80],\n",
    "    \"ada__n_estimators\" : [250],\n",
    "\n",
    "}\n",
    "\n",
    "temp_dict = {}\n",
    "t0 = time.time()\n",
    "\n",
    "ada_gs = GridSearchCV(ada_pipe,param_grid=ada_pipe_params,cv=5,verbose=1)\n",
    "\n",
    "ada_gs.fit(X_train,y_train)\n",
    "\n",
    "best_ada = ada_gs.best_estimator_\n",
    "\n",
    "ada_count += 1\n",
    "\n",
    "ada_gs.best_params_[\"train score\"] = best_ada.score(X_train,y_train)\n",
    "ada_gs.best_params_[\"test score\"] = best_ada.score(X_test,y_test)\n",
    "temp_dict[f'model_{ada_count}'] = ada_gs.best_params_\n",
    "\n",
    "temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "ada_model_df = pd.concat([ada_model_df,temp_df])\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'This took {t1-t0} seconds!')\n",
    "\n",
    "ada_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model_df.to_csv(\"../data/ada_model_params.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create dictionary of model params and counter\n",
    "svm_model_df = pd.read_csv(\"../data/svm_model_params.csv\")\n",
    "#getting the index from the nb_model_params and saving it to a count\n",
    "svm_count = svm_model_df.tail(1).index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] cvec__max_df=0.8, cvec__max_features=2500, cvec__min_df=2, svm__C=1, svm__degree=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvec__max_df=0.8, cvec__max_features=2500, cvec__min_df=2, svm__C=1, svm__degree=2, total= 4.0min\n",
      "[CV] cvec__max_df=0.8, cvec__max_features=2500, cvec__min_df=2, svm__C=1, svm__degree=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cvec__max_df=0.8, cvec__max_features=2500, cvec__min_df=2, svm__C=1, svm__degree=2, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 1340.445824623108 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>svm__C</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>svm__degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980128</td>\n",
       "      <td>0.917692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980128</td>\n",
       "      <td>0.917692</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980128</td>\n",
       "      <td>0.917692</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978205</td>\n",
       "      <td>0.913077</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978205</td>\n",
       "      <td>0.913077</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978205</td>\n",
       "      <td>0.913077</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cvec__max_df  cvec__max_features  cvec__min_df  svm__C  train score  \\\n",
       "0                 0.8                2500             2       1     0.980128   \n",
       "1                 0.8                2500             2       1     0.980128   \n",
       "2                 0.8                2500             2       1     0.980128   \n",
       "3                 0.8                2500             2       1     0.978205   \n",
       "4                 0.8                2500             2       1     0.978205   \n",
       "model_5           0.8                2500             2       1     0.978205   \n",
       "\n",
       "         test score  svm__degree  \n",
       "0          0.917692          NaN  \n",
       "1          0.917692          2.0  \n",
       "2          0.917692          2.0  \n",
       "3          0.913077          2.0  \n",
       "4          0.913077          2.0  \n",
       "model_5    0.913077          2.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords)),\n",
    "    ('to_dense' , DenseTransformer()),\n",
    "    ('ss', StandardScaler()),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "svm_pipe_params = {\n",
    "    \"cvec__max_features\" : [2500],\n",
    "    \"cvec__min_df\" : [2],\n",
    "    \"cvec__max_df\" : [.80],\n",
    "    \"svm__C\" : [1],\n",
    "    \"svm__degree\" : [2],\n",
    "}\n",
    "\n",
    "temp_dict = {}\n",
    "t0 = time.time()\n",
    "\n",
    "svm_gs = GridSearchCV(svm_pipe,param_grid=svm_pipe_params,cv=2,verbose=2)\n",
    "\n",
    "svm_gs.fit(X_train,y_train)\n",
    "\n",
    "best_svm = svm_gs.best_estimator_\n",
    "\n",
    "svm_count += 1\n",
    "\n",
    "svm_gs.best_params_[\"train score\"] = best_svm.score(X_train,y_train)\n",
    "svm_gs.best_params_[\"test score\"] = best_svm.score(X_test,y_test)\n",
    "temp_dict[f'model_{svm_count}'] = svm_gs.best_params_\n",
    "\n",
    "temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "svm_model_df = pd.concat([svm_model_df,temp_df])\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'This took {t1-t0} seconds!')\n",
    "\n",
    "svm_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_df.to_csv(\"../data/svm_model_params.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating using VoteClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0.9662820512820512\n",
      "Testing 0.933076923076923\n"
     ]
    }
   ],
   "source": [
    "vote = VotingClassifier([\n",
    "    (\"logreg\" , best_logreg),\n",
    "#     (\"knn\" , best_knn),\n",
    "    (\"nb\" , best_nb),\n",
    "#     (\"dt\" , best_dt),\n",
    "#     (\"rf\" , best_rf),\n",
    "#     (\"ada\" , best_ada),\n",
    "    (\"svm\" , best_svm)\n",
    "])\n",
    "\n",
    "vote.fit(X_train,y_train)\n",
    "\n",
    "print(f'Training {vote.score(X_train,y_train)}')\n",
    "print(f'Testing {vote.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with help on how to send pickle files to sepcific directory \n",
    "#https://stackoverflow.com/questions/17750422/how-to-pickle-an-object-to-a-certain-directory#:~:text=If%20you%20wish%20to%20save,added%20to%20a%20different%20machine.&text=Set%20root%20equal%20to%20your,%3D%20Path(%22.%22)\n",
    "#https://stackoverflow.com/questions/18474791/decreasing-the-size-of-cpickle-objects\n",
    "with open('../data/saved_models/nb_model.pkl', 'wb') as nb_file:\n",
    "    pickle.dump(best_nb, nb_file)\n",
    "\n",
    "with open('../data/saved_models/logreg_model.pkl', 'wb') as logreg_file:\n",
    "    pickle.dump(best_logreg, logreg_file)\n",
    "\n",
    "#using gzip to make sure svm model size is under the 100MB required for github\n",
    "with gzip.GzipFile('../data/saved_models/svm_model.pgz', 'w') as svm_file:\n",
    "    pickle.dump(best_svm, svm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
